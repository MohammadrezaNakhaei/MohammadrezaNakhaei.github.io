---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
<style>body {text-align: justify}</style>
I am a final year Ph.D. student at Computer Vision Group at Tampere University, under the joint supervision of Prof. Joni K√§m√§r√§inen and Joni Pajarinen (Aalto University). 

I have 6 years of interdisciplinary research and industrial experience in computer vision and robot learning/deep learning, and worked on **two academic-industrial cooperation projects** with **Co. Nokia**  and  **Co. Cargotec** (supervised by Dr.Juho Vihonen and Dr.Mohammad M. Aref).

My current research focuses on **visual representation learning**, **model-free imitation learning**, and **offline model-free reinforcement learning/planning**, with the goal of developing safe-AI solutions for real-world applications. My research outcomes have been published in top-tier international robot/AI conferences such as ICRA, IROS, NeurIPS, and resulted in one WO patent in the related fields (<a href='https://scholar.google.com/citations?user=0bTF5XUAAAAJ'>link </a>). In addition, I have served as a PC Member of various conferences, including BMVC, ICRA, IROS, and AAAI.





# üìù Publications 

##  Preprints


<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_offline_gcrl.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Swapped goal-conditioned offline Reinforcement Learning](https://arxiv.org/pdf/2302.08865), 
  - **Wenyan Yang**, Huiling Wang, Dingding Cai, Joni Pajarinen, Joni-Kristen K√§m√§r√§inen
  - `Preprint` arXiv, 2023
 
</div>
</div>


##  Conferences

<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_pger.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Prioritized offline Goal-swapping Experience Replay](https://arxiv.org/pdf/2302.07741) 
  - **Wenyan Yang**, Joni Pajarinen, Dinging Cai, Joni K√§m√§r√§inen
  - `ICLR RRL workshop 2023` 
 
</div>
</div>

<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_seq2seq.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Seq2Seq Imitation Learning for Tactile Feedback-based Manipulation](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0bTF5XUAAAAJ&sortby=pubdate&citation_for_view=0bTF5XUAAAAJ:W7OEmFMy1HYC)
  - **Wenyan Yang**, Alexandre Angleraud, Roel S. Pieters, Joni Pajarinen, Joni-Kristian Kamarainen  
  - `ICRA 2023` 
 
</div>
</div>

<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_cemd.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Constrained Imitation Q-learning with Earth Mover‚Äôs Distance reward](https://openreview.net/pdf?id=rzfPNkOyC7O)
  - **Wenyan Yang**, Nataliya Strokina, Joni Pajarinen, Joni-Kristian K√§m√§r√§inen 
  - `NeurIPS workshop 2022` 
 
</div>
</div>

<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_hybrid.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Monolithic vs. hybrid controller for multi-objective Sim-to-Real learning](https://ieeexplore.ieee.org/iel7/9635848/9635849/09636426.pdf)
  - Atakan Dag, Alexandre Angleraud, **Wenyan Yang**, Nataliya Strokina, Roel S Pieters, Minna Lanz, Joni-Kristian K√§m√§r√§inen  
  - `IROS 2022` 
 
</div>
</div>


<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_nn_pile.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Neural Network Controller for Autonomous Pile Loading Revised](https://ieeexplore.ieee.org/iel7/9560720/9560666/09561804.pdf)
  - **Wenyan Yang**, Nataliya Strokina, Nikolay Serbenyuk, Joni Pajarinen, Reza Ghabcheloo, Juho Vihonen, Mohammad M Aref, Joni-Kristian K√§m√§r√§inen  
  - `ICRA 2021` 
 
</div>
</div>


<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_rf_pile.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Learning a pile loading controller from demonstrations](https://ieeexplore.ieee.org/iel7/9187508/9196508/09196907.pdf)
  - **Wenyan Yang**, Nataliya Strokina, Nikolay Serbenyuk, Reza Ghabcheloo, Joni K√§m√§r√§inen  
  - `ICRA 2020` 
 
</div>
</div>


<div class='small-paper-box'>
  <div class='small-paper-box-image'><div>
  <img src='images/wenyan_yang_360.png' alt="sym" width="100%"></div></div>
  <div class='small-paper-box-text' markdown="1">

  [Object detection in equirectangular panorama](https://ieeexplore.ieee.org/iel7/8527858/8545020/08546070.pdf)
  - **Wenyan Yang**, Yanlin Qian, Joni-Kristian K√§m√§r√§inen, Francesco Cricri, Lixin Fan 
  - `ICPR 2018`
 
</div>
</div>


##  Journal

- `Frontiers in Robotics and AI` [Visual Rewards From Observation for Sequential Tasks: Autonomous Pile Loading](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9194444/), Nataliya Strokina, **Wenyan Yang**, Joni Pajarinen, Nikolay Serbenyuk, Joni K√§m√§r√§inen, Reza Ghabcheloo


##  Patent

- `WO Patent` [Method and apparatus for relative positioning of a spreader](https://patents.google.com/patent/WO2022008793A1/en?oq=WO2022008793A1)
**Wenyan Yang**, Mohammad Aref, Juho Vihonen, Jyri Lukkala, Mikko Asikainen, Hannu Santahuhta


## üìöOthers
- `ECCV VOT challenge 2022` [The Tenth Visual Object Tracking VOT2022 Challenge Results](https://link.springer.com/chapter/10.1007/978-3-031-25085-9_25), Matej Kristan, Ales Leonardis, Jiri Matas, Michael Felsberg, Roman Pflugfelder, Joni-Kristian Kamarainen, Hyung Jin Chang,MartinDanelljan,LukaCÀáehovinZajc,AlanLukezÀáicÀá, Ondrej Drbohlav, Johanna Bjorklund, Yushan Zhang, Zhongqun Zhang, Song Yan, **Wenyan Yang**, Dingding Cai, Christoph Mayer, and Gustavo Fernandez.




# üë®‚Äçüíª Projects

## Industrial projects

[**Autonomous Industrial Crane Controller (Co. Cargotec)**]
  - *2019 - 2022.12*

  - [DSII]() project with Co. Cargotec.

  - The heavy load transportation industry often involves the handling of large and weighty loads, particularly during the loading and unloading of vehicles in harbor and shipyard settings. One of the key tools used in container logistics is the spreader, which is mounted on crane systems to lift and move containers. Unfortunately, this equipment is typically operated by a human operator who requires extensive training to become proficient in using the spreader control system, making it prone to human errors.

  - We designed a reinforcement learning-based controller for industrial cranes to handle autonomous container logistics. The research outcomes with a [WO patent](https://patents.google.com/patent/WO2022008793A1/en?oq=WO2022008793A1) and a deliverable solution on the real cranes.




[**360 Video Object Detection Project (Co. Nokia)**]
  - *2017 - 2018*
 
  - In this research work, we deliver a solution of object detection in 360¬∞ videos for the NOKIA OZO camera. The project aims at implementing object detection features on the OZO camera to enable its use in real-world applications, such as detecting if construction workers are following safety instructions.

  - The research outcomes with a novel panoramic object detection dataset and a YOLO-based 360¬∞ image object detection baseline ([link](https://github.com/uenian33/360_object_detection_dataset)). 



## Other projects

<div class='paper-box'>
  <div class='paper-box-image'><div>
  <img src='images/wenyan_yang_depth.png' alt="sym" width="100%"></div></div>
  <div class='paper-box-text' markdown="1">


  [**Depth Image Data augmentation**]
  -  Generating SGM calculated disparity estimation from monocular RGB image. This project provides a python based library which generates stereo disparity map from a single image input. This project can be used as data augmentation for generating real depth camera like depth images. ([link](https://github.com/uenian33/mono2SGM))

</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'><div>
  <img src='images/wenyan_yang_grasp.png' alt="sym" width="100%"></div></div>
  <div class='paper-box-text' markdown="1">

  [**General graping controller for Motoman NX100**]
  -  This project implements a depth image-based object grasping pose estimator for Motoman NX100.
  - [GitHub](https://github.com/uenian33/nx100_robotic_tasks)
  - [Vid](https://www.youtube.com/watch?v=NBE9e7AJw6I)

</div>
</div>





# üéñ Experiences

## Technical skills

-Programming: Proficient in Python and past experience with C, C++, Java, MATLAB and other languages.

-Tools: Proficient in PyTorch, Numpy, OpenCV, Git, Bash, etc. Experience with TensorFlow, ROS, JAX, etc.



<br/><br/>







